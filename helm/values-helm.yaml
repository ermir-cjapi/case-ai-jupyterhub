# JupyterHub Helm Values - Kubernetes Deployment
# This is the same as jupyterhub_config.py but in YAML format for Kubernetes

proxy:
  # Generate with: openssl rand -hex 32
  secretToken: "a7c63b7d74e9628282eca95874fa7a9f69797f027512bb6d9f0636bb9689307e"
  service:
    type: NodePort  # Expose on fixed port for Cloudflare tunnel
    nodePorts:
      http: 30080  # Fixed port - update Cloudflare to localhost:30080
  https:
    enabled: false  # Cloudflare handles TLS

hub:
  # ============================================
  # USE HELM CHART 4.0.0 HUB IMAGE
  # ============================================
  # Override to ensure we get oauthenticator v17+
  # Chart 4.0.0 uses hub image 3.3.8
  # ============================================
  image:
    name: quay.io/jupyterhub/k8s-hub
    tag: "3.3.8"
  
  service:
    type: ClusterIP
  db:
    type: sqlite-pvc  # Simple SQLite database
  
  config:
    JupyterHub:
      admin_access: true
  
  # ============================================
  # MOUNT EXTERNAL PYTHON FILE
  # ============================================
  # The azure_ad_auth.py file is mounted via ConfigMap
  # (created automatically by deploy_jhub_helm.sh)
  # ============================================
  extraVolumes:
    - name: azure-auth-script
      configMap:
        name: azure-auth-script
  
  extraVolumeMounts:
    - name: azure-auth-script
      mountPath: /etc/jupyterhub/scripts
      readOnly: true
  
  # ============================================
  # AZURE AD CREDENTIALS FROM KUBERNETES SECRET
  # ============================================
  # Credentials are stored securely in Kubernetes secret.
  # 
  # To create the secret, run on your NVIDIA server:
  #   cd helm && ./create-azure-secret.sh
  #
  # This loads environment variables from the secret:
  # ============================================
  extraEnv:
    # Crypt key for auth_state encryption (required for group management)
    JUPYTERHUB_CRYPT_KEY:
      value: "2ed5854441fcd1d787df21fde8d18ead1ccd886b40cf9cbc48e2ae794e141eb4"
    AZURE_TENANT_ID:
      valueFrom:
        secretKeyRef:
          name: jupyterhub-azure-oauth
          key: tenant-id
    AZURE_CLIENT_ID:
      valueFrom:
        secretKeyRef:
          name: jupyterhub-azure-oauth
          key: client-id
    AZURE_CLIENT_SECRET:
      valueFrom:
        secretKeyRef:
          name: jupyterhub-azure-oauth
          key: client-secret
  
  extraConfig:
    # ============================================
    # ENSURE DEPENDENCIES ARE AVAILABLE
    # ============================================
    # Install required packages if not already present.
    # This is a safety net in case the Helm chart's base image is outdated.
    # ============================================
    00-verify-dependencies: |
      import subprocess
      import sys
      
      print("=" * 80)
      print("ðŸ“¦ Verifying dependencies...")
      print("=" * 80)
      
      # Check oauthenticator version
      result = subprocess.run(
          [sys.executable, "-m", "pip", "show", "oauthenticator"],
          capture_output=True, text=True
      )
      
      for line in result.stdout.split('\n'):
          if line.startswith('Version:'):
              version = line.split(':')[1].strip()
              major_version = int(version.split('.')[0])
              print(f"âœ… oauthenticator: v{version}")
              
              if major_version < 17:
                  print(f"âš ï¸  WARNING: v{version} is too old!")
                  print(f"   Need v17+ for allowed_groups and admin_groups")
                  print(f"   Check hub image version in values-helm.yaml")
              break
      
      # Verify requests library
      try:
          import requests
          print(f"âœ… requests: available")
      except ImportError:
          print(f"âŒ requests: not found (installing...)")
          subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "requests"])
          print(f"âœ… requests: installed")
      
      print("=" * 80)
    
    # ============================================
    # AZURE AD AUTHENTICATION WITH GRAPH API
    # ============================================
    # Implementation is in external file: helm/azure_ad_auth.py
    # Mounted at: /etc/jupyterhub/scripts/azure_ad_auth.py
    #
    # Why external file?
    # - Cleaner separation of concerns
    # - Easier to test Python code independently
    # - Better code organization
    # 
    # See: azure-doc/AZURE-AD-FREE-TIER-SOLUTION.md
    # ============================================
    01-azure-ad-auth: |
      import os
      
      # Load external Python file with Azure AD implementation
      print("ðŸ“‚ Loading Azure AD auth from external file...")
      exec(open('/etc/jupyterhub/scripts/azure_ad_auth.py').read(), globals())
      
      # Verify the class was loaded
      print(f"âœ… AzureAdGraphAuthenticator class loaded: {AzureAdGraphAuthenticator}")
      
      # ============================================
      # CREDENTIALS FROM KUBERNETES SECRET
      # ============================================
      c.AzureAdOAuthenticator.tenant_id = os.environ.get('AZURE_TENANT_ID')
      c.AzureAdOAuthenticator.client_id = os.environ.get('AZURE_CLIENT_ID')
      c.AzureAdOAuthenticator.client_secret = os.environ.get('AZURE_CLIENT_SECRET')
      c.AzureAdOAuthenticator.oauth_callback_url = "https://jupyterhub.ccrolabs.com/hub/oauth_callback"
      
      # MUST enable auth_state to store access_token for Graph API
      c.Authenticator.enable_auth_state = True
      
      # Use our custom authenticator (defined in azure_ad_auth.py)
      c.JupyterHub.authenticator_class = AzureAdGraphAuthenticator
      c.AzureAdGraphAuthenticator.manage_groups = True
      
      print(f"âœ… Authenticator set to: {c.JupyterHub.authenticator_class}")
      
      # ============================================
      # GROUP-BASED AUTHORIZATION
      # ============================================
      # IMPORTANT: Use Group Object IDs (not names!)
      # 
      # Why Object IDs?
      # - Group names can be changed in Azure AD
      # - Object IDs are permanent UUIDs
      # - More reliable and secure
      #
      # How to find Object IDs:
      # 1. Azure Portal â†’ Groups â†’ [Your Group] â†’ Overview
      # 2. Copy "Object ID" field
      # 
      # Or check hub logs after login to see:
      #   - JupyterHub-Admins: d6c49ed5-eefc-48c4-90d0-2026f5fe3916
      #   - JupyterHub-Users: 6543851f-fd97-40e8-b097-ab5a71e44ef2
      # ============================================
      
      # Allow these groups to access JupyterHub
      c.AzureAdGraphAuthenticator.allowed_groups = {
          "d6c49ed5-eefc-48c4-90d0-2026f5fe3916",  # JupyterHub-Admins
          "6543851f-fd97-40e8-b097-ab5a71e44ef2",  # JupyterHub-Users
          "4fb32c31-b135-43d5-a00e-9e566e6aceff"   # (check logs for name)
      }
      
      # Grant admin privileges to this group
      c.AzureAdGraphAuthenticator.admin_groups = {
          "d6c49ed5-eefc-48c4-90d0-2026f5fe3916"   # JupyterHub-Admins
      }
      
      print("âœ… Azure AD auth configuration complete")

singleuser:
  image:
    # Official JupyterHub base with GPU libraries
    name: docker.io/ermircjapi/jupyterhub-notebook
    tag: v2.3  # PyTorch nightly for RTX 5090 support (sm_120)
    pullPolicy: Always
  
  storage:
    type: dynamic
    capacity: 10Gi
    dynamic:
      storageClass: local-path  # k3s creates storage automatically
  
  # Start in JupyterLab
  defaultUrl: /lab
  
  # Fix PVC permissions using fsGroup
  extraPodConfig:
    securityContext:
      fsGroup: 100
      fsGroupChangePolicy: "OnRootMismatch"
  
  # Disable cloud metadata blocking (requires privileged init container)
  cloudMetadata:
    blockWithIptables: false
  
  # ============================================
  # USER PROFILES - Choose CPU or GPU at login
  # ============================================
  # Users select profile when logging in:
  # - CPU Only: Always available, for data exploration/light work
  # - GPU Enabled: Limited to 8 concurrent users (with time-slicing)
  # ============================================
  
  profileList:
    - display_name: "ðŸ’» CPU Only - Data Exploration"
      description: |
        ðŸš€ Always available (no waiting)
        ðŸ“Š Perfect for: data analysis, visualization, pandas/numpy
        âš¡ 2 CPUs, 4GB RAM
        âŒ No GPU access
      default: true
      kubespawner_override:
        cpu_limit: 2
        cpu_guarantee: 0.5
        mem_limit: "4G"
        mem_guarantee: "1G"
        # No GPU resources
    
    - display_name: "ðŸŽ® GPU Enabled - ML/AI Training"
      description: |
        ðŸ”¥ 1 GPU slice (RTX 5090)
        ðŸ¤– Perfect for: PyTorch, TensorFlow, deep learning
        âš¡ 4 CPUs, 8GB RAM, 1 GPU
        â³ May queue if 8 users active
      kubespawner_override:
        cpu_limit: 4
        cpu_guarantee: 1
        mem_limit: "8G"
        mem_guarantee: "2G"
        extra_resource_limits:
          nvidia.com/gpu: "1"
        extra_resource_guarantees:
          nvidia.com/gpu: "1"
  
  # ============================================
  # GPU TIME-SLICING CONFIGURATION
  # ============================================
  # IMPORTANT: GPU Time-Slicing must be configured first!
  # See: GPU-SHARING.md for details
  # 
  # With time-slicing enabled (replicas=8):
  # - 1 physical GPU becomes 8 virtual GPUs
  # - 8 users can work simultaneously on GPU profile
  # - Each gets ~12.5% when all active, 100% when alone
  # - Unlimited users on CPU-only profile
  #
  # Without time-slicing (default):
  # - Only 1 user at a time per physical GPU
  # - Other users wait in queue (Pending pods)
  #
  # To enable time-slicing on your cluster (RUN ONCE):
  #   ./setup-gpu-timeslicing.sh
  # ============================================

# Auto-shutdown idle notebooks
cull:
  enabled: true
  timeout: 3600   # 1 hour
  every: 600      # check every 10 minutes

# Keep image pulled
prePuller:
  continuous:
    enabled: true

# Disable user-scheduler (use default K3s scheduler)
scheduling:
  userScheduler:
    enabled: false
