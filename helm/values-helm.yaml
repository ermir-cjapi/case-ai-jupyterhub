# JupyterHub Helm Values - Kubernetes Deployment
# This is the same as jupyterhub_config.py but in YAML format for Kubernetes

proxy:
  # Generate with: openssl rand -hex 32
  secretToken: "a7c63b7d74e9628282eca95874fa7a9f69797f027512bb6d9f0636bb9689307e"
  service:
    type: NodePort  # Expose on fixed port for Cloudflare tunnel
    nodePorts:
      http: 30080  # Fixed port - update Cloudflare to localhost:30080
  https:
    enabled: false  # Cloudflare handles TLS

hub:
  # ============================================
  # USE LATEST HUB IMAGE
  # ============================================
  # Chart 4.0.0 default image has oauthenticator v16
  # Use 4.0.0 tag which should have v17+
  # If not, the upgrade script below will handle it
  # ============================================
  image:
    name: quay.io/jupyterhub/k8s-hub
    tag: "4.0.0"
  
  service:
    type: ClusterIP
  db:
    type: sqlite-pvc  # Simple SQLite database
  
  config:
    JupyterHub:
      admin_access: true
  
  # ============================================
  # MOUNT EXTERNAL PYTHON FILE
  # ============================================
  # The azure_ad_auth.py file is mounted via ConfigMap
  # (created automatically by deploy_jhub_helm.sh)
  # ============================================
  extraVolumes:
    - name: azure-auth-script
      configMap:
        name: azure-auth-script
  
  extraVolumeMounts:
    - name: azure-auth-script
      mountPath: /etc/jupyterhub/scripts
      readOnly: true
  
  # ============================================
  # AZURE AD CREDENTIALS FROM KUBERNETES SECRET
  # ============================================
  # Credentials are stored securely in Kubernetes secret.
  # 
  # To create the secret, run on your NVIDIA server:
  #   cd helm && ./create-azure-secret.sh
  #
  # This loads environment variables from the secret:
  # ============================================
  extraEnv:
    # Crypt key for auth_state encryption (required for group management)
    JUPYTERHUB_CRYPT_KEY:
      value: "2ed5854441fcd1d787df21fde8d18ead1ccd886b40cf9cbc48e2ae794e141eb4"
    AZURE_TENANT_ID:
      valueFrom:
        secretKeyRef:
          name: jupyterhub-azure-oauth
          key: tenant-id
    AZURE_CLIENT_ID:
      valueFrom:
        secretKeyRef:
          name: jupyterhub-azure-oauth
          key: client-id
    AZURE_CLIENT_SECRET:
      valueFrom:
        secretKeyRef:
          name: jupyterhub-azure-oauth
          key: client-secret
    # Optional: explicit resource / audience for the JupyterHub app.
    # If not set, we fall back to AZURE_CLIENT_ID in extraConfig.
    AZURE_APP_RESOURCE:
      valueFrom:
        secretKeyRef:
          name: jupyterhub-azure-oauth
          key: app-resource
  
  extraConfig:
    # ============================================
    # ENSURE DEPENDENCIES ARE AVAILABLE
    # ============================================
    # Install required packages if not already present.
    # This is a safety net in case the Helm chart's base image is outdated.
    # ============================================
    00-ensure-dependencies: |
      import subprocess
      import sys
      
      print("=" * 80)
      print("üì¶ Checking dependencies...")
      print("=" * 80)
      
      # Check oauthenticator version
      result = subprocess.run(
          [sys.executable, "-m", "pip", "show", "oauthenticator"],
          capture_output=True, text=True
      )
      
      needs_upgrade = False
      for line in result.stdout.split('\n'):
          if line.startswith('Version:'):
              version = line.split(':')[1].strip()
              major_version = int(version.split('.')[0])
              print(f"üìå oauthenticator: v{version}")
              
              if major_version < 17:
                  print(f"‚ö†Ô∏è  v{version} is too old (need v17+)")
                  print(f"üîß Upgrading...")
                  needs_upgrade = True
              else:
                  print(f"‚úÖ v{version} is OK (v17+)")
              break
      
      # Upgrade if needed
      if needs_upgrade:
          subprocess.check_call([
              sys.executable, "-m", "pip", "install", 
              "--upgrade", "--no-deps", "oauthenticator>=17.0.0"
          ])
          print(f"‚úÖ oauthenticator upgraded to v17+")
      
      # Ensure requests
      try:
          import requests
          print(f"‚úÖ requests: available")
      except ImportError:
          subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "requests"])
          print(f"‚úÖ requests: installed")
      
      print("=" * 80)
    
    # ============================================
    # AZURE AD AUTHENTICATION WITH GRAPH API
    # ============================================
    # Implementation is in external file: helm/azure_ad_auth.py
    # Mounted at: /etc/jupyterhub/scripts/azure_ad_auth.py
    #
    # Why external file?
    # - Cleaner separation of concerns
    # - Easier to test Python code independently
    # - Better code organization
    # 
    # See: azure-doc/AZURE-AD-FREE-TIER-SOLUTION.md
    # ============================================
    01-azure-ad-auth: |
      import os
      
      # Load external Python file with Azure AD implementation
      print("üìÇ Loading Azure AD auth from external file...")
      exec(open('/etc/jupyterhub/scripts/azure_ad_auth.py').read(), globals())
      
      # Verify the class was loaded
      print(f"‚úÖ AzureAdGraphAuthenticator class loaded: {AzureAdGraphAuthenticator}")
      
      # ============================================
      # CREDENTIALS FROM KUBERNETES SECRET
      # ============================================
      c.AzureAdOAuthenticator.tenant_id = os.environ.get('AZURE_TENANT_ID')
      c.AzureAdOAuthenticator.client_id = os.environ.get('AZURE_CLIENT_ID')
      c.AzureAdOAuthenticator.client_secret = os.environ.get('AZURE_CLIENT_SECRET')
      c.AzureAdOAuthenticator.oauth_callback_url = "https://jupyterhub.ccrolabs.com/hub/oauth_callback"

      # ============================================
      # FIX ACCESS TOKEN AUDIENCE FOR OBO FLOW
      # ============================================
      # Force the access_token to have our app as the audience (not Graph API).
      # This is required for the On-Behalf-Of (OBO) flow to work.
      #
      # In oauthenticator v17+, we must explicitly request an access token
      # for our own app by adding it to the scope.
      client_id = os.environ.get("AZURE_CLIENT_ID")
      if client_id:
          # Request token with our app as audience using the client_id/.default format
          c.AzureAdOAuthenticator.scope = [
              "openid",
              "email",
              "profile",
              f"{client_id}/.default"  # This requests a token for our app
          ]
          print(f"‚úÖ AzureAdOAuthenticator.scope set to include app audience: {client_id}/.default")
      else:
          print("‚ö†Ô∏è WARNING: AZURE_CLIENT_ID not found, cannot set proper scope!")
      
      # MUST enable auth_state to store access_token for Graph API
      c.Authenticator.enable_auth_state = True
      
      # Use our custom authenticator (defined in azure_ad_auth.py)
      c.JupyterHub.authenticator_class = AzureAdGraphAuthenticator
      c.AzureAdGraphAuthenticator.manage_groups = True
      # We implement our own allowed_groups/admin_groups checks; disable
      # oauthenticator's built-in auth_state_groups_key handling to avoid
      # noisy log errors when 'user.groups' is not present.
      
      print(f"‚úÖ Authenticator set to: {c.JupyterHub.authenticator_class}")
      
      # ============================================
      # GROUP-BASED AUTHORIZATION
      # ============================================
      # IMPORTANT: Use Group Object IDs (not names!)
      # 
      # Why Object IDs?
      # - Group names can be changed in Azure AD
      # - Object IDs are permanent UUIDs
      # - More reliable and secure
      #
      # How to find Object IDs:
      # 1. Azure Portal ‚Üí Groups ‚Üí [Your Group] ‚Üí Overview
      # 2. Copy "Object ID" field
      # 
      # Or check hub logs after login to see:
      #   - JupyterHub-Admins: d6c49ed5-eefc-48c4-90d0-2026f5fe3916
      #   - JupyterHub-Users: 6543851f-fd97-40e8-b097-ab5a71e44ef2
      # ============================================
      
      # Allow these groups to access JupyterHub
      c.AzureAdGraphAuthenticator.allowed_groups = {
          "d6c49ed5-eefc-48c4-90d0-2026f5fe3916",  # JupyterHub-Admins
          "6543851f-fd97-40e8-b097-ab5a71e44ef2",  # JupyterHub-Users
          "4fb32c31-b135-43d5-a00e-9e566e6aceff"   # (check logs for name)
      }
      
      # Grant admin privileges to this group
      c.AzureAdGraphAuthenticator.admin_groups = {
          "d6c49ed5-eefc-48c4-90d0-2026f5fe3916"   # JupyterHub-Admins
      }
      
      print("‚úÖ Azure AD auth configuration complete")

singleuser:
  image:
    # Official JupyterHub base with GPU libraries
    name: docker.io/ermircjapi/jupyterhub-notebook
    tag: v2.3  # PyTorch nightly for RTX 5090 support (sm_120)
    pullPolicy: Always
  
  storage:
    type: dynamic
    capacity: 10Gi
    dynamic:
      storageClass: local-path  # k3s creates storage automatically
  
  # Start in JupyterLab
  defaultUrl: /lab
  
  # Fix PVC permissions using fsGroup
  extraPodConfig:
    securityContext:
      fsGroup: 100
      fsGroupChangePolicy: "OnRootMismatch"
  
  # Disable cloud metadata blocking (requires privileged init container)
  cloudMetadata:
    blockWithIptables: false
  
  # ============================================
  # USER PROFILES - Choose CPU or GPU at login
  # ============================================
  # Users select profile when logging in:
  # - CPU Only: Always available, for data exploration/light work
  # - GPU Enabled: Limited to 8 concurrent users (with time-slicing)
  # ============================================
  
  profileList:
    - display_name: "üíª CPU Only - Data Exploration"
      description: |
        üöÄ Always available (no waiting)
        üìä Perfect for: data analysis, visualization, pandas/numpy
        ‚ö° 2 CPUs, 4GB RAM
        ‚ùå No GPU access
      default: true
      kubespawner_override:
        cpu_limit: 2
        cpu_guarantee: 0.5
        mem_limit: "4G"
        mem_guarantee: "1G"
        # No GPU resources
    
    - display_name: "üéÆ GPU Enabled - ML/AI Training"
      description: |
        üî• 1 GPU slice (RTX 5090)
        ü§ñ Perfect for: PyTorch, TensorFlow, deep learning
        ‚ö° 4 CPUs, 8GB RAM, 1 GPU
        ‚è≥ May queue if 8 users active
      kubespawner_override:
        cpu_limit: 4
        cpu_guarantee: 1
        mem_limit: "8G"
        mem_guarantee: "2G"
        extra_resource_limits:
          nvidia.com/gpu: "1"
        extra_resource_guarantees:
          nvidia.com/gpu: "1"
  
  # ============================================
  # GPU TIME-SLICING CONFIGURATION
  # ============================================
  # IMPORTANT: GPU Time-Slicing must be configured first!
  # See: GPU-SHARING.md for details
  # 
  # With time-slicing enabled (replicas=8):
  # - 1 physical GPU becomes 8 virtual GPUs
  # - 8 users can work simultaneously on GPU profile
  # - Each gets ~12.5% when all active, 100% when alone
  # - Unlimited users on CPU-only profile
  #
  # Without time-slicing (default):
  # - Only 1 user at a time per physical GPU
  # - Other users wait in queue (Pending pods)
  #
  # To enable time-slicing on your cluster (RUN ONCE):
  #   ./setup-gpu-timeslicing.sh
  # ============================================

# Auto-shutdown idle notebooks
cull:
  enabled: true
  timeout: 3600   # 1 hour
  every: 600      # check every 10 minutes

# Keep image pulled
prePuller:
  continuous:
    enabled: true

# Disable user-scheduler (use default K3s scheduler)
scheduling:
  userScheduler:
    enabled: false
