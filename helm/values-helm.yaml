# JupyterHub Helm Values - Kubernetes Deployment
# This is the same as jupyterhub_config.py but in YAML format for Kubernetes

proxy:
  # Generate with: openssl rand -hex 32
  secretToken: "a7c63b7d74e9628282eca95874fa7a9f69797f027512bb6d9f0636bb9689307e"
  service:
    type: NodePort  # Expose on fixed port for Cloudflare tunnel
    nodePorts:
      http: 30080  # Fixed port - update Cloudflare to localhost:30080
  https:
    enabled: false  # Cloudflare handles TLS

hub:
  service:
    type: ClusterIP
  db:
    type: sqlite-pvc  # Simple SQLite database
  config:
    JupyterHub:
      admin_access: true
  
  extraConfig:
    # ============================================
    # AZURE AD / ENTRA ID AUTHENTICATION
    # ============================================
    # Setup Instructions:
    # 1. Go to Azure Portal ‚Üí Microsoft Entra ID ‚Üí App registrations
    # 2. Click "New registration"
    # 3. Fill in:
    #    - Name: JupyterHub Production
    #    - Supported account types: Single tenant (Accounts in this organizational directory only)
    #    - Redirect URI: Web ‚Üí https://jupyterhub.ccrolabs.com/hub/oauth_callback
    # 4. After creation, go to "Overview" and copy:
    #    - Application (client) ID ‚Üí CLIENT_ID below
    #    - Directory (tenant) ID ‚Üí TENANT_ID below
    # 5. Go to "Certificates & secrets" ‚Üí New client secret ‚Üí Copy secret value ‚Üí CLIENT_SECRET below
    # 6. Go to "API permissions":
    #    - Add permission ‚Üí Microsoft Graph ‚Üí Delegated permissions
    #    - Add: email, openid, profile, User.Read
    #    - (For group-based access): Also add GroupMember.Read.All
    #    - Click "Grant admin consent" button
    # 7. Update the values below with your credentials
    # ============================================
    00-azure-ad-auth: |
      from oauthenticator.azuread import AzureAdOAuthenticator
      c.JupyterHub.authenticator_class = AzureAdOAuthenticator
      
      # ============================================
      # PASTE YOUR CREDENTIALS HERE (from app registration):
      # ============================================
      # After creating your app registration, replace these values:
      # - Get Tenant ID and Client ID from: App Registration ‚Üí Overview
      # - Get Client Secret from: App Registration ‚Üí Certificates & secrets
      # 
      # ‚ö†Ô∏è SECURITY: For production, use Kubernetes secrets instead of plaintext!
      # See: AZURE-AD-AUTH-QUICK-REFERENCE.md (Template 5)
      # ============================================
      
      c.AzureAdOAuthenticator.tenant_id = "b73221da-cbb5-4c98-9434-b0665273141a"
      c.AzureAdOAuthenticator.client_id = "9144a933-3898-411a-b358-e7288a89bcde"
      c.AzureAdOAuthenticator.client_secret = "c77adb97-b987-43d1-904b-8193aa7f9223"
      c.AzureAdOAuthenticator.oauth_callback_url = "https://jupyterhub.ccrolabs.com/hub/oauth_callback"
      
      # ============================================
      # GROUP-BASED ACCESS CONTROL (RECOMMENDED)
      # ============================================
      # Create these groups in Azure AD:
      # 1. JupyterHub-Users (Security group) - Regular users
      # 2. JupyterHub-Admins (Security group) - Administrators
      #
      # To add users: Azure AD ‚Üí Groups ‚Üí [Group Name] ‚Üí Members ‚Üí Add members
      # Changes take effect on next user login (no JupyterHub redeploy needed!)
      # ============================================
      
      # Users in these Azure AD groups can access JupyterHub
      c.AzureAdOAuthenticator.allowed_groups = {
          "JupyterHub-Users",      # Regular users with standard access
          "JupyterHub-Admins"      # Admins need access too!
      }
      
      # Users in this Azure AD group will have admin privileges
      c.AzureAdOAuthenticator.admin_groups = {
          "JupyterHub-Admins"      # Admins can manage servers and access user notebooks
      }
      
      # ============================================
      # ALTERNATIVE: Email-Based Access Control (Not Recommended)
      # ============================================
      # If you prefer email-based control instead of groups, comment out the
      # allowed_groups and admin_groups above, and uncomment these:
      #
      # c.Authenticator.allowed_users = {
      #     "user1@yourcompany.com",
      #     "user2@yourcompany.com"
      # }
      # c.Authenticator.admin_users = {
      #     "admin@yourcompany.com"
      # }
      #
      # NOTE: Requires JupyterHub redeploy to add/remove users!
      # ============================================

    # ============================================
    # ALTERNATIVE: GitHub OAuth (Commented out)
    # ============================================
    # 00-github-auth: |
    #   from oauthenticator.github import GitHubOAuthenticator
    #   c.JupyterHub.authenticator_class = GitHubOAuthenticator
    #   
    #   c.GitHubOAuthenticator.client_id = "Ov23lidtVx7ofQPm6Qvz"
    #   c.GitHubOAuthenticator.client_secret = "ef282ca998be6a552b00f3ccfe62f18f195a9eae"
    #   c.GitHubOAuthenticator.oauth_callback_url = "https://jupyterhub.ccrolabs.com/hub/oauth_callback"
    #   c.Authenticator.allow_all = True
    #   c.Authenticator.admin_users = {"your-github-username"}
    
    # ============================================
    # ALTERNATIVE: No Authentication (Testing only)
    # ============================================
    # 00-simple-auth: |
    #   from jupyterhub.auth import DummyAuthenticator
    #   c.JupyterHub.authenticator_class = DummyAuthenticator
    #   c.DummyAuthenticator.password = ""
    #   c.Authenticator.admin_users = {"admin"}

singleuser:
  image:
    # Official JupyterHub base with GPU libraries
    name: docker.io/ermircjapi/jupyterhub-notebook
    tag: v2.3  # PyTorch nightly for RTX 5090 support (sm_120)
    pullPolicy: Always
  
  storage:
    type: dynamic
    capacity: 10Gi
    dynamic:
      storageClass: local-path  # k3s creates storage automatically
  
  # Start in JupyterLab
  defaultUrl: /lab
  
  # Fix PVC permissions using fsGroup
  extraPodConfig:
    securityContext:
      fsGroup: 100
      fsGroupChangePolicy: "OnRootMismatch"
  
  # Disable cloud metadata blocking (requires privileged init container)
  cloudMetadata:
    blockWithIptables: false
  
  # ============================================
  # USER PROFILES - Choose CPU or GPU at login
  # ============================================
  # Users select profile when logging in:
  # - CPU Only: Always available, for data exploration/light work
  # - GPU Enabled: Limited to 8 concurrent users (with time-slicing)
  # ============================================
  
  profileList:
    - display_name: "üíª CPU Only - Data Exploration"
      description: |
        üöÄ Always available (no waiting)
        üìä Perfect for: data analysis, visualization, pandas/numpy
        ‚ö° 2 CPUs, 4GB RAM
        ‚ùå No GPU access
      default: true
      kubespawner_override:
        cpu_limit: 2
        cpu_guarantee: 0.5
        mem_limit: "4G"
        mem_guarantee: "1G"
        # No GPU resources
    
    - display_name: "üéÆ GPU Enabled - ML/AI Training"
      description: |
        üî• 1 GPU slice (RTX 5090)
        ü§ñ Perfect for: PyTorch, TensorFlow, deep learning
        ‚ö° 4 CPUs, 8GB RAM, 1 GPU
        ‚è≥ May queue if 8 users active
      kubespawner_override:
        cpu_limit: 4
        cpu_guarantee: 1
        mem_limit: "8G"
        mem_guarantee: "2G"
        extra_resource_limits:
          nvidia.com/gpu: "1"
        extra_resource_guarantees:
          nvidia.com/gpu: "1"
  
  # ============================================
  # GPU TIME-SLICING CONFIGURATION
  # ============================================
  # IMPORTANT: GPU Time-Slicing must be configured first!
  # See: GPU-SHARING.md for details
  # 
  # With time-slicing enabled (replicas=8):
  # - 1 physical GPU becomes 8 virtual GPUs
  # - 8 users can work simultaneously on GPU profile
  # - Each gets ~12.5% when all active, 100% when alone
  # - Unlimited users on CPU-only profile
  #
  # Without time-slicing (default):
  # - Only 1 user at a time per physical GPU
  # - Other users wait in queue (Pending pods)
  #
  # To enable time-slicing on your cluster (RUN ONCE):
  #   ./setup-gpu-timeslicing.sh
  # ============================================

# Auto-shutdown idle notebooks
cull:
  enabled: true
  timeout: 3600   # 1 hour
  every: 600      # check every 10 minutes

# Keep image pulled
prePuller:
  continuous:
    enabled: true

# Disable user-scheduler (use default K3s scheduler)
scheduling:
  userScheduler:
    enabled: false
